---
title: "Machine learning models"
author: "Christelle Colin-Leitzinger"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: false
    theme: united
    highlight: pygments
    df_print: paged
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
.figure {
   margin-top: 25px;
   margin-bottom: 10px;
}

table {
    margin-top: 10px;
    margin-bottom: 25px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      cache = FALSE,
                      fig.align='center'
                      )
```


```{r library}
library(tidyverse)
library(tidymodels)
library(themis)
```


```{r load}
omics_data <- read_delim(paste0(here::here(), "/lusq_reprocess_2021-12-08_iron_log2_merged.txt")) %>% 
  janitor::clean_names()
metabolites_data <- read_delim(paste0(here::here(), "/hmdb_keep_v3_python_blessed.txt")) %>% 
  janitor::clean_names()
```

```{r data prep}
# Imputation
omics_data <- omics_data %>% 
  mutate(across((starts_with("x06")), .fns = ~ replace_na(., min(., na.rm = TRUE))))

mldata <- omics_data %>% 
  # Filter identified metabolites
  filter(non_heavy_identified_flag == 1 & !is.na(hmdb) & !str_detect(hmdb, "\\|")) %>% 
  # Join with known metabolites
  inner_join(., metabolites_data %>% 
              select(accession, taxonomy_super_class),
            by = c("hmdb" = "accession")) %>% 
  filter(!is.na(taxonomy_super_class))

test_data <- omics_data %>% 
  # Filter identified metabolites
  filter(non_heavy_identified_flag != 1) %>% 
  select(hmdb, row_id, 
         row_m_z, row_retention_time,
         starts_with("x06"))
```

# Data
The data is imputed with minimum of the expression.  
I focused on predicting Lipids Yes vs No by building the model on Lipids and Organic acids data in the training set.  

# Build a model
I use the whole identified metabolites data as a training set and will use 10 fold cross validation to evaluate the performance of the models.  

```{r}
# skimr::skim(mldata)
train_data <- mldata %>% 
  select(hmdb, row_m_z, row_retention_time, 
         starts_with("x06"), taxonomy_super_class) %>% 
  group_by(taxonomy_super_class) %>% 
  mutate(number_sample_class = n()) %>% 
  ungroup() %>% 
  # mutate(taxonomy_super_class = case_when(
  #   number_sample_class <= 5               ~ "Others",
  #   TRUE                                   ~ taxonomy_super_class
  # )) %>% 
  # filter(number_sample_class > 5) %>% 
  filter(str_detect(taxonomy_super_class, "Lipids|acids")) %>%
  mutate(is_lipids = case_when(
    str_detect(taxonomy_super_class, "Lipids")              ~ "Yes",
    TRUE                                                    ~ "No"
  )) %>% 
  select(-number_sample_class, -taxonomy_super_class) %>% 
  mutate_if(is.character, factor)

# skimr::skim(train_data)
# summary(train_data)
```

## Build a recipe

```{r recipe}
# Recipe : data pre processing and features engineering + imputation
mldata_recipe <-
  # 1.model formula
  recipe(is_lipids ~ ., data = train_data)  %>% 
  # 2.keep these variables but not use them as either outcomes or predictors
  update_role(hmdb, new_role = "ID") %>% 
  # Use nearest neighbor to create new synthetic observation almost similar
  step_smote(is_lipids)
mldata_recipe
```
- 1 Id = hmdb, 1 outcome = is_lipids, 89 predictors = row_m_z + row_retention_time + samples  
- the models use `step_smote` to balance the cases in the training set. It use nearest neighbor to create new synthetic observation almost similar.  
- Use a 10 fold cross validation to train and evaluate model on the training set This allow us to pick the best values for the hyperparameters of the random forest model  
```{r}
set.seed(123)

mldata_folds <- vfold_cv(train_data, strata = is_lipids)
```

<!-- ## Build model -->

<!-- # RANDOM FOREST -->
```{r rand_forest}
# Model specification
set.seed(345)

ranger_spec <- rand_forest(
  mtry = tune(), 
  min_n = tune(),
  trees = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

# Set up a workflow container
ranger_workflow <- 
  workflow() %>% 
  # Add preprocessor
  add_recipe(mldata_recipe) %>%
  add_model(ranger_spec)

# Tuning
# doParallel::registerDoParallel()

set.seed(345)

ranger_tune <-
  tune_grid(ranger_workflow, 
            resamples = mldata_folds, 
            grid = 20) # Try the 20 candidate point with each min_n and mtry
```


```{r xgboost}
xgboost_spec <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), 
             loss_reduction = tune(), sample_size = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost") 
xgboost_workflow <- 
  workflow() %>% 
  add_recipe(mldata_recipe) %>% 
  add_model(xgboost_spec) 
set.seed(345)
xgboost_tune <-
  tune_grid(xgboost_workflow, resamples = mldata_folds, grid = 10)
```

```{r}
glmnet_spec <- 
  logistic_reg(penalty = tune(), mixture = tune()) %>% # Looks ridge would increase really slightly mixture = 0
  set_mode("classification") %>% 
  set_engine("glmnet") 
glmnet_workflow <- 
  workflow() %>% 
  add_recipe(mldata_recipe) %>% 
  add_model(glmnet_spec) 
glmnet_grid <- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), mixture = c(0, 0.05, 
                                                                                      0.2, 0.4, 0.6, 0.8, 1)) 
set.seed(345)
glmnet_tune <- 
  tune_grid(glmnet_workflow, resamples = mldata_folds, grid = glmnet_grid) 
```

```{r}
kknn_spec <- 
  nearest_neighbor(neighbors = tune(), weight_func = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 
kknn_workflow <- 
  workflow() %>% 
  add_recipe(mldata_recipe) %>% 
  add_model(kknn_spec) 
set.seed(345)
kknn_tune <-
  tune_grid(kknn_workflow, 
            resamples = mldata_folds, 20)
```


```{r Explore Tuning Results}
set.seed(678)

final_rf <- ranger_workflow %>% 
  finalize_workflow(select_best(ranger_tune, "accuracy"))
final_xgboost <- xgboost_workflow %>% 
  finalize_workflow(select_best(xgboost_tune, "roc_auc"))
final_glmnet <- glmnet_workflow %>% 
  finalize_workflow(select_best(glmnet_tune, "roc_auc"))
final_kknn <- kknn_workflow %>% 
  finalize_workflow(select_best(kknn_tune, "roc_auc"))
```

These are the hyperpareameters value on our random forest
```{r hyperpareameters}
final_rf
final_glmnet
```
<br>

***

```{r fit_resamples}
set.seed(789)
rf_results <- final_rf %>% 
  fit_resamples( 
    resamples = mldata_folds,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_resamples(save_pred = TRUE, verbose = TRUE)
  )
set.seed(789)
xgboost_results <- final_xgboost %>% 
  fit_resamples(
    resamples = mldata_folds,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_resamples(save_pred = TRUE)
  )
set.seed(789)
glmnet_results <- final_glmnet %>% 
  fit_resamples(
    resamples = mldata_folds,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_resamples(save_pred = TRUE)
  )
set.seed(789)
kknn_results <- final_kknn %>% 
  fit_resamples(
    resamples = mldata_folds,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_resamples(save_pred = TRUE)
  )
```

# Evaluate models
```{r Performance Metrics}
rf_results %>% # Compare both models
  collect_metrics() %>% 
  select(".metric", rf_mean = mean) %>% 
  full_join(., glmnet_results %>% 
              collect_metrics() %>% 
              select(".metric", glmet_mean = mean), by = ".metric") %>% 
  full_join(., xgboost_results %>% 
              collect_metrics() %>% 
              select(".metric", xgboost_mean = mean), by = ".metric") %>% 
  full_join(., kknn_results %>% 
              collect_metrics() %>% 
              select(".metric", kknn_mean = mean), by = ".metric")

rf_results %>% # Compare both models
  collect_metrics() %>% 
  mutate(model = "rf") %>% 
  bind_rows(glmnet_results %>% 
              collect_metrics() %>% 
              mutate(model = "glmnet")) %>% 
  bind_rows(xgboost_results %>% 
              collect_metrics() %>% 
              mutate(model = "xgboost")) %>% 
  bind_rows(kknn_results %>% 
              collect_metrics() %>% 
              mutate(model = "kknn")) %>% 
  
  ggplot(aes(x= .metric, y=mean, fill = model))+
  geom_bar(stat = "identity",
           position = position_dodge())+
  geom_errorbar(aes(x = .metric,
                    ymin = mean - std_err,
                    ymax = mean + std_err),
                width = 0.2, alpha = 0.5,
                position=position_dodge(width=0.9))+
  theme_minimal()+
  scale_fill_viridis_d(option = "A")
```
roc-auc and accuracy show a really good performance. The sensitivity (ability to detect a true positive) and specificity are good.

```{r evaluate models}
rf_results %>% # Compare both models
  collect_predictions() %>% 
  mutate(model = "rf") %>% 
  bind_rows(glmnet_results %>% 
              collect_predictions() %>% 
              mutate(model = "glmnet")) %>% 
  bind_rows(xgboost_results %>% 
              collect_predictions() %>% 
              mutate(model = "xgboost")) %>% 
  bind_rows(kknn_results %>% 
              collect_predictions() %>% 
              mutate(model = "kknn")) %>% 
  group_by(model) %>% 
  roc_curve(is_lipids, .pred_No) %>% 
  autoplot()
```
<br>
<br>

```{r evaluate models2}
df <- rf_results %>% 
  collect_predictions()
conf_tab <- table(df$is_lipids, df$.pred_class)
conf_tab <- conf_tab / rowSums(conf_tab)
conf_tab <- as.data.frame(conf_tab, stringsAsFactors = TRUE)
conf_tab$Var2 <- factor(conf_tab$Var2, rev(levels(conf_tab$Var2)))

ggplot(conf_tab, aes(Var1, Var2, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = scales::percent(Freq))) +
  scale_fill_gradient(low = "white", high = "#3575b5")+
  labs(x = "Truth", y = "Prediction", title = "Confusion matrix for Ramdom Forest",
       fill = "Valid prediction")+
  theme_minimal()

rf_results %>%
  collect_predictions() %>%
  conf_mat(is_lipids, .pred_class)

df <- glmnet_results %>% 
  collect_predictions()
conf_tab <- table(df$is_lipids, df$.pred_class)
conf_tab <- conf_tab / rowSums(conf_tab)
conf_tab <- as.data.frame(conf_tab, stringsAsFactors = TRUE)
conf_tab$Var2 <- factor(conf_tab$Var2, rev(levels(conf_tab$Var2)))

ggplot(conf_tab, aes(Var1, Var2, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = scales::percent(Freq))) +
  scale_fill_gradient(low = "white", high = "#3575b5")+
  labs(x = "Truth", y = "Prediction", title = "Confusion matrix for Logistic Regression",
       fill = "Valid prediction")+
  theme_minimal()

glmnet_results %>%
  collect_predictions() %>%
  conf_mat(is_lipids, .pred_class)
```
Overall prediction estimate for ramdom forest on the cross validation set is `r rf_results %>% collect_predictions() %>% ppv(truth = is_lipids, estimate = .pred_class) %>% select(.estimate)`  
Overall prediction estimate for logistic regression on the cross validation set is `r glmnet_results %>% collect_predictions() %>% ppv(truth = is_lipids, estimate = .pred_class) %>% select(.estimate)`

<br>

***

# Prediction on non identified metabolites : Lipids Yes / No (Ramdom forest)
```{r fit on testing RF}
############################################################################################### AT LAST
# Step finalize Fit : fitting to the whole training and evaluating on the testing data
# With the model of our choice
set.seed(101)

last_fit <- final_rf %>% 
  fit(train_data)

test_fit <- last_fit %>% 
  predict(test_data)

predicted_metabolites <- test_data %>% 
  bind_cols(., test_fit) %>% 
  rename(is_lipids = .pred_class) %>% 
  mutate(pred = "prediction") %>% 
  bind_rows(., train_data %>%  
              mutate(pred = "measured"))


predicted_metabolites %>% 
  ggplot(aes(x=row_m_z, row_retention_time, color= pred))+
  geom_point()+
  theme_minimal()+
  facet_wrap(. ~ is_lipids, ncol = 2)
```

# Prediction on non identified metabolites : Lipids Yes / No (Logistic Regression)
```{r}
############################################################################################### AT LAST
# Step finalize Fit : fitting to the whole training and evaluating on the testing data
# With the model of our choice
set.seed(101)

last_fit <- final_glmnet %>% 
  fit(train_data)

test_fit <- last_fit %>% 
  predict(test_data)

predicted_metabolites <- test_data %>% 
  bind_cols(., test_fit) %>% 
  rename(is_lipids = .pred_class) %>% 
  mutate(pred = "prediction") %>% 
  bind_rows(., train_data %>%  
              mutate(pred = "measured"))


predicted_metabolites %>% 
  ggplot(aes(x=row_m_z, row_retention_time, color= pred))+
  geom_point()+
  theme_minimal()+
  facet_wrap(. ~ is_lipids, ncol = 2)
```

<br>







