---
title: "Machine learning models"
author: "Christelle Colin-Leitzinger"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: false
    theme: united
    highlight: pygments
    df_print: paged
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
.figure {
   margin-top: 25px;
   margin-bottom: 10px;
}

table {
    margin-top: 10px;
    margin-bottom: 25px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      cache = FALSE,
                      fig.align='center'
                      )
```


```{r library}
library(tidyverse)
library(tidymodels)
library(themis)
```


```{r load}
omics_data <- read_delim(paste0(here::here(), "/lusq_reprocess_2021-12-08_iron_log2_merged.txt")) %>% 
  janitor::clean_names()
metabolites_data <- read_delim(paste0(here::here(), "/hmdb_keep_v3_python_blessed.txt")) %>% 
  janitor::clean_names()
```

```{r data prep}
# Imputation
omics_data <- omics_data %>% 
  mutate(across((starts_with("x06")), .fns = ~ replace_na(., min(., na.rm = TRUE))))

mldata <- omics_data %>% 
  # Filter identified metabolites
  filter(non_heavy_identified_flag == 1 & !is.na(hmdb) & !str_detect(hmdb, "\\|")) %>% 
  # Join with known metabolites
  inner_join(., metabolites_data %>% 
              select(accession, taxonomy_super_class),
            by = c("hmdb" = "accession")) %>% 
  filter(!is.na(taxonomy_super_class))

test_data <- omics_data %>% 
  # Filter identified metabolites
  filter(non_heavy_identified_flag != 1) %>% 
  select(hmdb, row_id, 
         row_m_z, row_retention_time,
         starts_with("x06"))
```

# Data
The data is imputed with minimum of the expression.  
I focused on predicting Lipids vs Organic acids.  

# Build a model
I use the whole identified metabolites data as a training set and will use 10 fold cross validation to evaluate the performance of the models.  

```{r}
# skimr::skim(mldata)
train_data <- mldata %>% 
  select(hmdb, row_m_z, row_retention_time, 
         starts_with("x06"), taxonomy_super_class) %>% 
  group_by(taxonomy_super_class) %>% 
  mutate(number_sample_class = n()) %>% 
  ungroup() %>% 
  # mutate(taxonomy_super_class = case_when(
  #   number_sample_class <= 5               ~ "Others",
  #   TRUE                                   ~ taxonomy_super_class
  # )) %>% 
  # filter(number_sample_class > 5) %>% 
  filter(str_detect(taxonomy_super_class, "Lipids|acids")) %>% 
  select(-number_sample_class) %>% 
  mutate_if(is.character, factor)

# skimr::skim(train_data)
# summary(train_data)
```

## Build a recipe

```{r recipe}
# Recipe : data pre processing and features engineering + imputation
mldata_recipe <-
  # 1.model formula
  recipe(taxonomy_super_class ~ ., data = train_data)  %>% 
  # 2.keep these variables but not use them as either outcomes or predictors
  update_role(hmdb, new_role = "ID") %>% 
  # Use nearest neighbor to create new synthetic observation almost similar
  step_smote(taxonomy_super_class)
mldata_recipe
```
- 1 Id = hmdb, 1 outcome = taxonomy_super_class, 89 predictors = row_m_z + row_retention_time + samples

- Use a 10 fold cross validation to train and evaluate model on the training set This allow us to pick the best values for the hyperparameters of the random forest model
```{r}
set.seed(123)

mldata_folds <- vfold_cv(train_data, strata = taxonomy_super_class)
```

<!-- ## Build model -->

<!-- # RANDOM FOREST -->
```{r rand_forest}
# Model specification
set.seed(345)

ranger_spec <- rand_forest(
  mtry = tune(), 
  min_n = tune(),
  trees = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

# Set up a workflow container
ranger_workflow <- 
  workflow() %>% 
  # Add preprocessor
  add_recipe(mldata_recipe) %>%
  add_model(ranger_spec)

# Tuning
# doParallel::registerDoParallel()

set.seed(345)

ranger_tune <-
  tune_grid(ranger_workflow, 
            resamples = mldata_folds, 
            grid = 20) # Try the 20 candidate point with each min_n and mtry
```

```{r Explore Tuning Results }
set.seed(678)

final_rf <- ranger_workflow %>% 
  finalize_workflow(select_best(ranger_tune, "accuracy"))
```

These are the hyperpareameters value on our random forest
```{r hyperpareameters}
final_rf
```
<br>

***

```{r fit_resamples}
set.seed(789)

rf_results <- final_rf %>% 
  fit_resamples( 
    resamples = mldata_folds,
    metrics = metric_set(roc_auc, accuracy, sensitivity, specificity),
    control = control_resamples(save_pred = TRUE, verbose = TRUE)
  )
```

# Evaluate models
```{r Performance Metrics}
collect_metrics(rf_results)
```
roc-auc show a good performance. The sensitivity (ability to detect a true positive) is low and specificity are high.

```{r evaluate models}
rf_results %>% 
  collect_metrics() %>% 
  mutate(model = "rf") %>% 
  ggplot(aes(x= .metric, y=mean))+
  geom_bar(stat = "identity",
           position = position_dodge())+
  geom_errorbar(aes(x = .metric,
                    ymin = mean - std_err,
                    ymax = mean + std_err),
                width = 0.2, alpha = 0.5,
                position=position_dodge(width=0.9))+
  theme_minimal()+
  scale_fill_viridis_d(option = "A")
```
<br>
<br>

```{r evaluate models2}
df <- rf_results %>% 
  collect_predictions()
conf_tab <- table(df$taxonomy_super_class, df$.pred_class)
conf_tab <- conf_tab / rowSums(conf_tab)
conf_tab <- as.data.frame(conf_tab, stringsAsFactors = TRUE)
conf_tab$Var2 <- factor(conf_tab$Var2, rev(levels(conf_tab$Var2)))

ggplot(conf_tab, aes(Var1, Var2, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = scales::percent(Freq))) +
  scale_fill_gradient(low = "white", high = "#3575b5")+
  labs(x = "Truth", y = "Prediction", title = "Confusion matrix",
       fill = "Valid prediction")+
  theme_minimal()

rf_results %>%
  collect_predictions() %>%
  conf_mat(taxonomy_super_class, .pred_class)
```
Overall prediction estimate on the cross validation set is `r rf_results %>% collect_predictions() %>% ppv(truth = taxonomy_super_class, estimate = .pred_class) %>% select(.estimate)`

<br>

***

# Prediction on non identified metabolites
```{r fit on testing RF}
############################################################################################### AT LAST
# Step finalize Fit : fitting to the whole training and evaluating on the testing data
# With the model of our choice
set.seed(101)

last_fit <- final_rf %>% 
  fit(train_data)

test_fit <- last_fit %>% 
  predict(test_data)

predicted_metabolites <- test_data %>% 
  bind_cols(., test_fit) %>% 
  rename(taxonomy_super_class = .pred_class) %>% 
  mutate(pred = "prediction") %>% 
  bind_rows(., train_data %>%  
            #   left_join(., omics_data %>% 
            #   select(row_id, row_m_z, row_retention_time,
            #          hmdb),
            # by = "hmdb"
            # ) %>% 
              mutate(pred = "measured"))


predicted_metabolites %>% 
  ggplot(aes(x=row_m_z, row_retention_time, color= pred))+
  geom_point()+
  theme_minimal()+
  facet_wrap(. ~ taxonomy_super_class, ncol = 2)
```


<br>







